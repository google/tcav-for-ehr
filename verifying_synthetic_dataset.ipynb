{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZQv4A5njBaj"
      },
      "source": [
        "# Verifying Synthetic Dataset\n",
        "\n",
        "In this colab, we provide some basic plotting and printing commands to explore the synthetic dataset and confirm that the data distribution matches the configured causal graph.\n",
        "\n",
        "Note: This colab was built to support the data config used in the main paper. This means there are a couple of assumptions:\n",
        "* The dataset has been saved as a .pkl file (this is how the provided dataset generating script saves datasets).\n",
        "* A single batch element can be plotted without causing a memory failure.\n",
        "* There are two labels, and each has a 1-dimensional, 2-element contingency table based on a single concept's binary values.\n",
        "* Each feature is influenced by a single concept.  \n",
        "\n",
        "If your dataset violates any of these assumptions, you will have to update the code to fit your use case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "executionInfo": {
          "elapsed": 416001,
          "status": "ok",
          "timestamp": 1604974940369,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          },
          "user_tz": 300
        },
        "id": "5fmU5lJ4LEui"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "\n",
        "import pprint\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "import dataset_specs\n",
        "import dataset_utils\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9v5A9iz4LHdf"
      },
      "outputs": [],
      "source": [
        "#@title Load Dataset\n",
        "\n",
        "dataset_filename = \"enter .pkl dataset filename here\" #@param {type: \"string\"}\n",
        "dataset = dataset_utils.load_pickled_data(dataset_filename)\n",
        "print(dataset.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tWNDIBbCQsNx"
      },
      "outputs": [],
      "source": [
        "#@title Verify Data Config\n",
        "#@markdown We print the dataset config below in order to reveal how we encode the causal graph. Some notes on the various config keys:\n",
        "#@markdown * feature_specs: A list of specs describing each feature in the dataset. Each spec encodes characteristic such as mean, noise, and \n",
        "#@markdown pattern-related parameters.\n",
        "#@markdown * concept_specs: A list of specs describing each concept in the dataset. Each concept spec contains: \n",
        "#@markdown  * a list of affected feature indexes\n",
        "#@markdown  * a mapping from affected feature index to the feature's agreement with that concept, as described in the paper\n",
        "#@markdown  * a mapping from affected feature index to the temporal feature pattern that the affected feature should exhibit when activated.\n",
        "#@markdown * label_specs: A list of specs describing each label in the dataset. This spec includes a list of indexes for the concepts that influence it,\n",
        "#@markdown and a binary contingency table that has a rank which matches the number of concept indexes.\n",
        "#@markdown * num_trains: number of batch elements in the training split.\n",
        "#@markdown * num_tests: number of batch elements in the validation \u0026 test splits.\n",
        "#@markdown * scaling_type: the scaling type used for the numerical features.\n",
        "#@markdown * seed: The RNG seed used to ensure a deterministic data generation process.\n",
        "\n",
        "pprint.pprint(dataset[\"config\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6pJEndCeRWnQ"
      },
      "outputs": [],
      "source": [
        "#@title Verify Data Shapes\n",
        "#@markdown Confirm that the shapes of each of the dataset split elements make sense, and that the number of batch elements in the training\n",
        "#@markdown and test splits match the num_trains and num_tests config parameters above. Below is a description of each dataset split field:\n",
        "#@markdown * sequence: Float sequence of features of shape [num_unroll, batch_size, ndims].\n",
        "#@markdown * label: Float array of labels of shape [num_unroll, batch_size, num_labels]\n",
        "#@markdown * concept: Bool array of concept indicators of shape [batch_size, num_concepts].\n",
        "#@markdown * concept_sequence: Int array of concept indicators on a timestep resolution of shape [num_unroll, batch_size, num_concepts].\n",
        "#@markdown * changes: Int array of concept changepoints of shape [batch_size, num_concepts].\n",
        "#@markdown * features: Bool array of concept-feature indicators of shape [batch_size, num_concepts, ndims]\n",
        "\n",
        "train_dataset = dataset[\"train_split\"]\n",
        "test_dataset = dataset[\"test_split\"]\n",
        "print(\"Example dataset split keys:\")\n",
        "print(train_dataset.keys())\n",
        "print()\n",
        "\n",
        "train_sequence = train_dataset[\"sequence\"]\n",
        "train_label = train_dataset[\"label\"]\n",
        "train_concepts = train_dataset[\"concept\"]\n",
        "train_concept_sequence = train_dataset[\"concept_sequence\"]\n",
        "train_changes = train_dataset[\"changes\"]\n",
        "train_features = train_dataset[\"features\"]\n",
        "\n",
        "print(\"train sequence shape:\", train_sequence.shape)\n",
        "print(\"train label shape:\", train_label.shape)\n",
        "print(\"train concepts shape:\", train_concepts.shape)\n",
        "print(\"train concept sequence shape:\", train_concept_sequence.shape)\n",
        "print(\"train changes shape:\", train_changes.shape)\n",
        "print(\"train features shape:\", train_features.shape)\n",
        "print()\n",
        "\n",
        "test_sequence = test_dataset[\"sequence\"]\n",
        "test_label = test_dataset[\"label\"]\n",
        "test_concepts = test_dataset[\"concept\"]\n",
        "test_concept_sequence = test_dataset[\"concept_sequence\"]\n",
        "test_changes = test_dataset[\"changes\"]\n",
        "test_features = test_dataset[\"features\"]\n",
        "\n",
        "print(\"test sequence shape:\", test_sequence.shape)\n",
        "print(\"test label shape:\", test_label.shape)\n",
        "print(\"test concepts shape:\", test_concepts.shape)\n",
        "print(\"test concept sequence shape:\", test_concept_sequence.shape)\n",
        "print(\"test changes shape:\", test_changes.shape)\n",
        "print(\"test features shape:\", test_features.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tDdEawY0T5y3"
      },
      "outputs": [],
      "source": [
        "#@title Plot Example Sequence\n",
        "\n",
        "example_idx = 6 #@param {type: 'integer'}\n",
        "\n",
        "#@markdown Below we print information for a single batch element, indexed by the value provided above, and plot its feature values.\n",
        "\n",
        "#@markdown We also plot the label values as well to see how they coincide with feature behavior.\n",
        "\n",
        "example_train_sequence = train_sequence[:, example_idx, :]\n",
        "example_train_label = train_label[:, example_idx, :]\n",
        "example_train_concepts = train_concepts[example_idx, :]\n",
        "example_train_concept_sequence = train_concept_sequence[:, example_idx, :]\n",
        "example_train_changes = train_changes[example_idx, :]\n",
        "example_train_features = train_features[example_idx, :, :]\n",
        "\n",
        "print(\"example train sequence shape:\", example_train_sequence.shape)\n",
        "print(\"example train label shape:\", example_train_label.shape)\n",
        "print(\"example train concept sequence shape:\", example_train_concept_sequence.shape)\n",
        "print(\"example train concepts shape:\", example_train_concepts.shape)\n",
        "print(\"example train concepts:\", example_train_concepts)\n",
        "print(\"example train changes shape:\", example_train_changes.shape)\n",
        "print(\"example train changes:\", example_train_changes)\n",
        "print(\"example train features shape:\", example_train_features.shape)\n",
        "print(\"example train features transposed:\")\n",
        "print(example_train_features.T)\n",
        "\n",
        "fig = plt.figure(figsize=(20, 5))\n",
        "ax = sns.heatmap(example_train_sequence.T, linewidth=0)\n",
        "ax.set_xlabel(\"Time\")\n",
        "ax.set_ylabel(\"Feature Index\")\n",
        "plt.show()\n",
        "\n",
        "fig = plt.figure(figsize=(16, 2))\n",
        "for i in range(2):\n",
        "  plt.plot(example_train_label[:, i], label=f\"label {i}\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Label Value\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "JMotEIqgP68-"
      },
      "outputs": [],
      "source": [
        "#@title Verify Conditional Label Probabilities\n",
        "\n",
        "#@markdown Here, we compare the theoretical and experimental label probabilities conditioned on concept value.\n",
        "#@markdown The contingency table for each label gives us the theoretical label probabilities, and we filter the actual data to get experimental.\n",
        "\n",
        "# Max label over all timesteps in each batch element to get element-level labels\n",
        "train_batch_labels = np.max(train_label, axis=0)\n",
        "\n",
        "for label_idx in range(2):\n",
        "  print(f\"label idx: {label_idx}\")\n",
        "  concept_idx = dataset[\"config\"][\"label_specs\"][label_idx][\"concept_idxs\"][0]\n",
        "  theoretical_label_prob_conditioned_on_pos_concept = dataset[\"config\"][\"label_specs\"][label_idx][\"contingency_table\"][1]\n",
        "  exp_label_prob_conditioned_on_pos_concept = np.mean(train_batch_labels[train_concepts[:, concept_idx], label_idx])\n",
        "  theoretical_label_prob_conditioned_on_neg_concept = dataset[\"config\"][\"label_specs\"][label_idx][\"contingency_table\"][0]\n",
        "  exp_label_prob_conditioned_on_neg_concept = np.mean(train_batch_labels[np.invert(train_concepts[:, concept_idx]), label_idx])\n",
        "  print(f'theoretical label prob conditioned on pos concept: {theoretical_label_prob_conditioned_on_pos_concept}')\n",
        "  print(f\"experimental label prob conditioned on pos concept: {exp_label_prob_conditioned_on_pos_concept}\")\n",
        "  print()\n",
        "  print(f'theoretical label prob conditioned on neg concept: {theoretical_label_prob_conditioned_on_neg_concept}')\n",
        "  print(f\"experimental label prob conditioned on neg concept: {exp_label_prob_conditioned_on_neg_concept}\")\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "r4WimkGKnTf2"
      },
      "outputs": [],
      "source": [
        "#@title Verify Conditional Feature Probabilities\n",
        "\n",
        "#@markdown Here we do the same thing as above, but for feature probabilities. The term agreement may be confusing for those that are not familiar with\n",
        "#@markdown how the term is used in the paper. \n",
        "\n",
        "#@markdown As a refresher: We design our features to have symmetrical conditional probabilities, such that   \n",
        "#@markdown p(Feature | Concept) = p(No Feature| No Concept). We use the term agreement to refer to the probability that the feature will deterministically \n",
        "#@markdown match the concept value. If the feature does not deterministically match, we still allow it to match with a probability of 0.5. \n",
        "#@markdown This is why p(Feature | Concept) = p(No Feature| No Concept) = agreement + ((1 - agreement) / 2)\n",
        "\n",
        "for concept_idx, concept_spec in enumerate(dataset[\"config\"][\"concept_specs\"]):\n",
        "  concept_name = concept_spec[\"name\"]\n",
        "  print(f\"\\nConcept idx: {concept_idx} (name: {concept_name})\")\n",
        "  for feature_idx, feature_agreement in concept_spec[\"feature_idx_to_agreement\"].items():\n",
        "    theoretical_feature_prob_conditioned_on_pos_concept = feature_agreement + ((1 - feature_agreement) / 2)\n",
        "    exp_feature_prob_conditioned_on_pos_concept = np.mean(train_features[train_concepts[:, concept_idx], 0, feature_idx])\n",
        "    theoretical_feature_prob_conditioned_on_neg_concept = 1 - (feature_agreement + ((1 - feature_agreement) / 2))\n",
        "    exp_feature_prob_conditioned_on_neg_concept = np.mean(train_features[np.invert(train_concepts[:, concept_idx]), 0, feature_idx])\n",
        "    print(f\"feature idx: {feature_idx}\")\n",
        "    print(f\"theoretical feature prob conditioned on pos concept: {theoretical_feature_prob_conditioned_on_pos_concept}\")\n",
        "    print(f\"exp feature prob conditioned on pos concept: {exp_feature_prob_conditioned_on_pos_concept}\")\n",
        "    print(f\"theoretical feature prob conditioned on neg concept: {theoretical_feature_prob_conditioned_on_neg_concept}\")\n",
        "    print(f\"exp feature prob conditioned on neg concept: {exp_feature_prob_conditioned_on_neg_concept}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Yqx6mS0FraW"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "//learning/brain/research/health/colab:rl_colab_auditable",
        "kind": "shared"
      },
      "name": "Verifying The Synthetic Dataset.ipynb",
      "provenance": [
        {
          "file_id": "16hxDYKQzYLfbujvp8hW9DgBv2VByxco1",
          "timestamp": 1604613971664
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
